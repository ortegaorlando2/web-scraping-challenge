{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bridal-layout",
   "metadata": {},
   "source": [
    "## Website data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-intention",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMars():\n",
    "# Dependencies\n",
    "\n",
    "    from bs4 import BeautifulSoup as bs\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "    from selenium.webdriver import Chrome\n",
    "    from selenium.webdriver.support.ui import Select\n",
    "    from selenium import webdriver\n",
    "\n",
    "    #telling the Chrome driver where is the executable\n",
    "    driver = Chrome(executable_path='C:/Webdriver/bin/chromedriver')\n",
    "\n",
    "\n",
    "    #defining a string variable with the website url\n",
    "    url = \"https://mars.nasa.gov/news/\"\n",
    "\n",
    "    #Making a connection to the Nasa News website\n",
    "    r = requests.get(url)\n",
    "\n",
    "    #creating a soup object with the html data\n",
    "    soup = bs(r.text, 'html')\n",
    "\n",
    "    #Finding all the div tags in the soup\n",
    "    texto=soup.find_all('div')\n",
    "\n",
    "    # Opening the website\n",
    "    driver.get(url)\n",
    "\n",
    "\n",
    "    # getting the button by class name\n",
    "    button = driver.find_element_by_class_name(\"menu_icon\")\n",
    "\n",
    "\n",
    "    # clicking on the button\n",
    "    button.click()\n",
    "\n",
    "    #Defining a button for a reactive element which matches the request\n",
    "    button = driver.find_element_by_id(\"li_4\")\n",
    "\n",
    "\n",
    "    #click the button\n",
    "    button.click()\n",
    "\n",
    "    #saving the current url to a variable for automation\n",
    "    url2=driver.current_url\n",
    "    url2\n",
    "\n",
    "    #Connecting with the News and Events website\n",
    "    r2=requests.get(url2)\n",
    "\n",
    "    #creating a soup object with the html text from the Mars Nasa website news and events\n",
    "    soup2 = bs(r2.text, 'lxml')\n",
    "\n",
    "    #Looking for all the news and then selecting only the latest news \n",
    "    texto2=soup2.find_all('h3', class_=\"title\")\n",
    "    textoTitle=texto2[0].text.strip()\n",
    "\n",
    "    #defining the button content (reactive link) for the first news\n",
    "    button=driver.find_element_by_class_name('list_image')\n",
    "\n",
    "    #clicking button \n",
    "    button.click()\n",
    "\n",
    "    #Checking the url of the redirected website. Saving to a variable\n",
    "    url3=driver.current_url\n",
    "    url3\n",
    "\n",
    "    #connect to the website that contains the main news\n",
    "    r3=requests.get(url3)\n",
    "\n",
    "    #create a soup object for this website\n",
    "    soup3=bs(r3.text,'lxml')\n",
    "\n",
    "    #This is the first paragraph of the main text of these news\n",
    "    texto3=soup3.find('p')\n",
    "    texto3\n",
    "\n",
    "    #define a variable with the string of the Space facts website\n",
    "    url4='https://space-facts.com/mars/'\n",
    "\n",
    "    #Using requests to connect to Space Facts website\n",
    "    r4=requests.get(url4)\n",
    "\n",
    "    #creating a soup element for this website (Mars Facts)\n",
    "    soup4=bs(r4.text,'html')\n",
    "\n",
    "    #extracting html from website\n",
    "    texto4=soup4.find('table')\n",
    "    #texto4\n",
    "\n",
    "    #reading the html table from the website Mars Facts\n",
    "    table=pd.read_html(url4)\n",
    "    table[0]\n",
    "\n",
    "    #cresting a dataframe with the information extracted from Mars Facts\n",
    "    df=pd.DataFrame(table[0])\n",
    "    df.rename(columns = {0:'Property', 1:'Value'}, inplace = True)\n",
    "    df\n",
    "\n",
    "    #Converting the Mars facts to html code\n",
    "    t_html=pd.DataFrame.to_html(df)\n",
    "    #t_html\n",
    "\n",
    "\n",
    "    #website for the hemisphere images of Mars\n",
    "    url5='https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "\n",
    "\n",
    "\n",
    "    #executing the driver to automatically go to the website\n",
    "    driver.get(url5)\n",
    "\n",
    "    #Create a beautiful soup element with the the html \n",
    "    main=bs(r5.text,'lxml')\n",
    "    titles=main.find_all('div', class_='description')\n",
    "    #titles\n",
    "\n",
    "\n",
    "\n",
    "    #collecting the titles of the various images\n",
    "    In [1]: titlist=[]\n",
    "\n",
    "    try:\n",
    "        for tit in titles:\n",
    "            tititem=tit.find('h3').text\n",
    "            titlist.append(tititem)\n",
    "\n",
    "    except:\n",
    "        print(\"Something went wrong\")\n",
    "        print(titlist)\n",
    "\n",
    "\n",
    "\n",
    "    #including a wait for these websites because the response is not fast\n",
    "    driver.implicitly_wait(10)\n",
    "\n",
    "    #getting the references from the html script\n",
    "    elems = driver.find_elements_by_css_selector(\".description [href]\")\n",
    "    links = [elem.get_attribute('href') for elem in elems]\n",
    "    links\n",
    "\n",
    "    #defining a function to call several times the website and click on each image\n",
    "    def but1(tag):\n",
    "       ...:     urln=links[tag]\n",
    "       ...:     driver.get(urln)\n",
    "       ...:     button=driver.find_element_by_link_text(\"Sample\")\n",
    "       ...:     button.click()\n",
    "       ...:     urlimg=driver.current_url\n",
    "       ...:     return urlimg\n",
    "\n",
    "    #Extracting the links to the images from the website (these are not the downloadable ones)\n",
    "    urlimg=[]\n",
    "    for u in range(4):\n",
    "        addurl=but1(u)\n",
    "        urlimg.append(addurl)\n",
    "\n",
    "    print(urlimg)\n",
    "\n",
    "\n",
    "\n",
    "    #assigning a variable to the Mars images website\n",
    "    url6='https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg'\n",
    "\n",
    "    #testing the response of the website\n",
    "    r6=requests.get(url6, timeout=10)\n",
    "    r6\n",
    "\n",
    "    #inspecting the dataframe for images\n",
    "    pd.DataFrame({titlist[i]: links[i] for i in range(len(links))}, index=[0])\n",
    "\n",
    "    hemispheres=[]\n",
    "\n",
    "    # saving a list of dictionaries with Mars images information\n",
    "    for i in range(4):\n",
    "        dic={titlist[i]:links[i]}\n",
    "        hemispheres.append(dic)\n",
    "\n",
    "    #print(hemispheres)\n",
    "    return hemispheres, textoTitle, texto3, t_html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-salon",
   "metadata": {},
   "source": [
    "## Mongo and Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-screw",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "#Flask\n",
    "from flask import Flask, render_template, redirect\n",
    "#connection to MongoDb\n",
    "from pymongo import MongoClient\n",
    "# import jupyter notebook as a function\n",
    "import scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-cincinnati",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this creates Flask app\n",
    "Mars_app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-spoke",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-plane",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare mongo to upload the images dictionary \n",
    "    mongo_url = \"mongodb://localhost:27017\"\n",
    "    #pass Mongo URL to MongoClient constructor. Defines the connection\n",
    "    client = MongoClient(mongo_url)\n",
    "    #defines a unique handle on the Mongo database for this code\n",
    "    db = client.MarsPhotos_db\n",
    "    #handle to the connection to insert the data. Define the variable\n",
    "    #Mars_collection that will contain the data\n",
    "    Mars_collection=db.HemImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-danger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mars_info=getMars(hemispheres, textoTitle, texto3, t_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_Mars_images():\n",
    "    Mars_collection.insert_many(hemispheres)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-violence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_my_Mars():\n",
    "    Mars_collection = get_collection()\n",
    "    Images = Mars_collection.find()\n",
    "    return render_template(\"index.html\", HemImages=HemImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hemispheres=[{\"name\":\"key1Hemisphere\", \"link\":\"\"},{\"name\":\"key2Hemisphere\", \"link\":\"\"},\n",
    "# {\"name\":\"key3Hemisphere\", \"link\":\"\"},{\"name\":\"key4Hemisphere\", \"link\":\"\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def insert_facts_Mongo(): \n",
    "#     facts_lst = [{\"name\":\"key1Hemisphere\", \"link\":\"\"},{\"name\":\"key2Hemisphere\", \"link\":\"\"},\n",
    "#     {\"name\":\"key3Hemisphere\", \"link\":\"\"},{\"name\":\"key4Hemisphere\", \"link\":\"\"}]\n",
    "#     Mars_collection.insert_many(facts)\n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the route that will import dictionary\n",
    "@Mars_app.route(\"/scrape\")\n",
    "def scrape():\n",
    "    message = \"Welcome to my rough Mars API\"\n",
    "    Mars_collection=get_collection()\n",
    "    return render_template('index.html', text=message, dict=hemispheres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Mars_app.route(\"/\")\n",
    "def query():\n",
    "    WhatsNew = db.MarsNews_Mongo.find_one()\n",
    "    return render_template(\"index.html\", WhatsNew=WhatsNew)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-discipline",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Mars_app.route(\"/bio\")\n",
    "def bio():\n",
    "    return render_template(\"bio.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Mars_app.route(\"/Sources\")\n",
    "def index():\n",
    "    Sources_list=[\"https://mars.nasa.gov/news/\",\n",
    "                  \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\",\n",
    "                  \"https://space-facts.com/mars/\"]\n",
    "    return render_template(\"sources.html\",  Sources=Sources_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-passage",
   "metadata": {},
   "source": [
    "if __name__ == \"__main__\":\n",
    "    insert_Mars_images.run(debug=True)\n",
    "    Mars_app.run(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
